{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of undersampling on logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from src.models.ordinal_regression import OrdinalClassifier\n",
    "from src.utils.embeddings import retrieve_all_embeds\n",
    "from src.utils.files import load_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bin_clf = LogisticRegression(random_state=0, solver=\"lbfgs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_train, df_dev = load_dfs([\"data/train_cleaned_final.csv\", \"data/dev_cleaned_final.csv\"])\n",
    "embed = retrieve_all_embeds([(\"data/features/use.pkl.train\", \"data/features/xception.pkl.train\"), \n",
    "                              (\"data/features/use.pkl.dev\",\"data/features/xception.pkl.dev\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y = df_train[\"Overall_sentiment\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_dev = df_dev[\"Overall_sentiment\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_labels = list(df_train[\"Overall_sentiment\"].cat.categories.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_codes = list(set(y.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_ordinal_clf(clf, X, Y):\n",
    "    clf_ord = OrdinalClassifier(clf)\n",
    "    clf_ord.fit(X, Y)\n",
    "    return clf_ord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test_ordinal_clf(clf, X, Y, labels):\n",
    "    pred_proba = clf.predict_proba(X)\n",
    "    pred_cls = clf.predict(X)\n",
    "    report = classification_report(Y, pred_cls, labels=labels)\n",
    "    return {\"pred_cls\": pred_cls, \"pred_proba\": pred_proba, \"report\": report}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def print_res(res):\n",
    "    for k,v in res.items():\n",
    "        print(k)\n",
    "        print(*[r[\"report_str\"] for r in v])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fit_test_OR(X_train, y_train, X_test, y_test, labels, clf):\n",
    "    ord_clf = compute_ordinal_clf(clf, X_train, y_train)\n",
    "    res = test_ordinal_clf(ord_clf, X_test, y_test, labels)\n",
    "    print(res[\"report\"])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image only\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.34      0.12        80\n",
      "           1       0.31      0.47      0.38       302\n",
      "           2       0.58      0.17      0.26       618\n",
      "\n",
      "    accuracy                           0.27      1000\n",
      "   macro avg       0.32      0.33      0.25      1000\n",
      "weighted avg       0.46      0.27      0.29      1000\n",
      "\n",
      "text only\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.30      0.17        80\n",
      "           1       0.37      0.50      0.42       302\n",
      "           2       0.67      0.42      0.52       618\n",
      "\n",
      "    accuracy                           0.44      1000\n",
      "   macro avg       0.39      0.41      0.37      1000\n",
      "weighted avg       0.54      0.44      0.46      1000\n",
      "\n",
      "concatenated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.24      0.13        80\n",
      "           1       0.37      0.51      0.43       302\n",
      "           2       0.65      0.39      0.49       618\n",
      "\n",
      "    accuracy                           0.41      1000\n",
      "   macro avg       0.37      0.38      0.35      1000\n",
      "weighted avg       0.52      0.41      0.44      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import InstanceHardnessThreshold\n",
    "\n",
    "iht = InstanceHardnessThreshold(random_state=0, estimator=LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=4000))\n",
    "\n",
    "for item, (X_train, X_test) in embed.items():\n",
    "    print(item)\n",
    "    X_resampled, y_resampled = iht.fit_resample(X_train, y)\n",
    "    fit_test_OR(X_resampled, pd.Series(y_resampled), X_test, y_dev, y_codes, bin_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image only\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.21      0.09        80\n",
      "           1       0.31      0.55      0.40       302\n",
      "           2       0.65      0.18      0.28       618\n",
      "\n",
      "    accuracy                           0.29      1000\n",
      "   macro avg       0.34      0.31      0.26      1000\n",
      "weighted avg       0.50      0.29      0.30      1000\n",
      "\n",
      "text only\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.44      0.20        80\n",
      "           1       0.35      0.36      0.35       302\n",
      "           2       0.65      0.44      0.52       618\n",
      "\n",
      "    accuracy                           0.41      1000\n",
      "   macro avg       0.38      0.41      0.36      1000\n",
      "weighted avg       0.52      0.41      0.45      1000\n",
      "\n",
      "concatenated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.41      0.19        80\n",
      "           1       0.34      0.39      0.36       302\n",
      "           2       0.66      0.42      0.51       618\n",
      "\n",
      "    accuracy                           0.41      1000\n",
      "   macro avg       0.38      0.41      0.36      1000\n",
      "weighted avg       0.52      0.41      0.44      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "\n",
    "for item, (X_train, X_test) in embed.items():\n",
    "    print(item)\n",
    "    X_resampled, y_resampled = rus.fit_resample(X_train, y)\n",
    "    fit_test_OR(X_resampled, pd.Series(y_resampled), X_test, y_dev, y_codes, bin_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image only\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.86      0.16        80\n",
      "           1       0.34      0.11      0.17       302\n",
      "           2       0.64      0.10      0.18       618\n",
      "\n",
      "    accuracy                           0.17      1000\n",
      "   macro avg       0.35      0.36      0.17      1000\n",
      "weighted avg       0.50      0.17      0.17      1000\n",
      "\n",
      "text only\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.85      0.16        80\n",
      "           1       0.32      0.13      0.18       302\n",
      "           2       0.70      0.11      0.19       618\n",
      "\n",
      "    accuracy                           0.18      1000\n",
      "   macro avg       0.37      0.36      0.18      1000\n",
      "weighted avg       0.54      0.18      0.19      1000\n",
      "\n",
      "concatenated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.81      0.16        80\n",
      "           1       0.34      0.19      0.24       302\n",
      "           2       0.67      0.14      0.23       618\n",
      "\n",
      "    accuracy                           0.21      1000\n",
      "   macro avg       0.37      0.38      0.21      1000\n",
      "weighted avg       0.53      0.21      0.23      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "nm1 = NearMiss(version=1)\n",
    "\n",
    "for item, (X_train, X_test) in embed.items():\n",
    "    print(item)\n",
    "    X_resampled, y_resampled = nm1.fit_resample(X_train, y)\n",
    "    fit_test_OR(X_resampled, pd.Series(y_resampled), X_test, y_dev, y_codes,bin_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image only\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.38      0.12        80\n",
      "           1       0.32      0.23      0.27       302\n",
      "           2       0.62      0.36      0.46       618\n",
      "\n",
      "    accuracy                           0.32      1000\n",
      "   macro avg       0.34      0.32      0.28      1000\n",
      "weighted avg       0.49      0.32      0.37      1000\n",
      "\n",
      "text only\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.68      0.16        80\n",
      "           1       0.36      0.29      0.32       302\n",
      "           2       0.66      0.17      0.28       618\n",
      "\n",
      "    accuracy                           0.25      1000\n",
      "   macro avg       0.37      0.38      0.25      1000\n",
      "weighted avg       0.52      0.25      0.28      1000\n",
      "\n",
      "concatenated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.45      0.14        80\n",
      "           1       0.34      0.42      0.38       302\n",
      "           2       0.68      0.22      0.33       618\n",
      "\n",
      "    accuracy                           0.30      1000\n",
      "   macro avg       0.37      0.36      0.28      1000\n",
      "weighted avg       0.53      0.30      0.33      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nm2 = NearMiss(version=2)\n",
    "\n",
    "for item, (X_train, X_test) in embed.items():\n",
    "    print(item)\n",
    "    X_resampled, y_resampled = nm2.fit_resample(X_train, y)\n",
    "    fit_test_OR(X_resampled, pd.Series(y_resampled), X_test, y_dev, y_codes, bin_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image only\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.33      0.12        80\n",
      "           1       0.37      0.19      0.25       302\n",
      "           2       0.61      0.50      0.55       618\n",
      "\n",
      "    accuracy                           0.39      1000\n",
      "   macro avg       0.35      0.34      0.31      1000\n",
      "weighted avg       0.50      0.39      0.42      1000\n",
      "\n",
      "text only\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.41      0.16        80\n",
      "           1       0.37      0.45      0.41       302\n",
      "           2       0.66      0.32      0.43       618\n",
      "\n",
      "    accuracy                           0.37      1000\n",
      "   macro avg       0.38      0.40      0.33      1000\n",
      "weighted avg       0.53      0.37      0.41      1000\n",
      "\n",
      "concatenated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.50      0.19        80\n",
      "           1       0.36      0.38      0.37       302\n",
      "           2       0.64      0.35      0.45       618\n",
      "\n",
      "    accuracy                           0.37      1000\n",
      "   macro avg       0.37      0.41      0.34      1000\n",
      "weighted avg       0.51      0.37      0.41      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nm3 = NearMiss(version=3)\n",
    "\n",
    "for item, (X_train, X_test) in embed.items():\n",
    "    print(item)\n",
    "    X_resampled, y_resampled = nm3.fit_resample(X_train, y)\n",
    "    fit_test_OR(X_resampled, pd.Series(y_resampled), X_test, y_dev, y_codes, bin_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.06      0.06        80\n",
      "           1       0.00      0.00      0.00       302\n",
      "           2       0.62      0.91      0.73       618\n",
      "\n",
      "    accuracy                           0.57      1000\n",
      "   macro avg       0.22      0.32      0.27      1000\n",
      "weighted avg       0.39      0.57      0.46      1000\n",
      "\n",
      "text only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.29      0.17        80\n",
      "           1       0.00      0.00      0.00       302\n",
      "           2       0.64      0.83      0.72       618\n",
      "\n",
      "    accuracy                           0.53      1000\n",
      "   macro avg       0.25      0.37      0.30      1000\n",
      "weighted avg       0.40      0.53      0.46      1000\n",
      "\n",
      "concatenated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.28      0.17        80\n",
      "           1       0.00      0.00      0.00       302\n",
      "           2       0.62      0.82      0.70       618\n",
      "\n",
      "    accuracy                           0.53      1000\n",
      "   macro avg       0.25      0.36      0.29      1000\n",
      "weighted avg       0.39      0.53      0.45      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "\n",
    "enn = EditedNearestNeighbours()\n",
    "\n",
    "for item, (X_train, X_test) in embed.items():\n",
    "    print(item)\n",
    "    X_resampled, y_resampled = enn.fit_resample(X_train, y)\n",
    "    fit_test_OR(X_resampled, pd.Series(y_resampled), X_test, y_dev, y_codes, bin_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.06      0.06        80\n",
      "           1       0.00      0.00      0.00       302\n",
      "           2       0.62      0.91      0.73       618\n",
      "\n",
      "    accuracy                           0.57      1000\n",
      "   macro avg       0.22      0.32      0.27      1000\n",
      "weighted avg       0.39      0.57      0.46      1000\n",
      "\n",
      "text only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.29      0.17        80\n",
      "           1       0.00      0.00      0.00       302\n",
      "           2       0.64      0.83      0.72       618\n",
      "\n",
      "    accuracy                           0.53      1000\n",
      "   macro avg       0.25      0.37      0.30      1000\n",
      "weighted avg       0.40      0.53      0.46      1000\n",
      "\n",
      "concatenated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.28      0.17        80\n",
      "           1       0.00      0.00      0.00       302\n",
      "           2       0.62      0.82      0.70       618\n",
      "\n",
      "    accuracy                           0.53      1000\n",
      "   macro avg       0.25      0.36      0.29      1000\n",
      "weighted avg       0.39      0.53      0.45      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RepeatedEditedNearestNeighbours\n",
    "\n",
    "renn = RepeatedEditedNearestNeighbours()\n",
    "\n",
    "for item, (X_train, X_test) in embed.items():\n",
    "    print(item)\n",
    "    X_resampled, y_resampled = renn.fit_resample(X_train, y)\n",
    "    fit_test_OR(X_resampled, pd.Series(y_resampled), X_test, y_dev, y_codes, bin_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        80\n",
      "           1       0.00      0.00      0.00       302\n",
      "           2       0.62      1.00      0.76       618\n",
      "\n",
      "    accuracy                           0.61      1000\n",
      "   macro avg       0.21      0.33      0.25      1000\n",
      "weighted avg       0.38      0.61      0.47      1000\n",
      "\n",
      "text only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.04      0.06        80\n",
      "           1       0.00      0.00      0.00       302\n",
      "           2       0.62      0.98      0.76       618\n",
      "\n",
      "    accuracy                           0.61      1000\n",
      "   macro avg       0.25      0.34      0.27      1000\n",
      "weighted avg       0.39      0.61      0.47      1000\n",
      "\n",
      "concatenated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.05      0.08        80\n",
      "           1       0.00      0.00      0.00       302\n",
      "           2       0.62      0.98      0.76       618\n",
      "\n",
      "    accuracy                           0.61      1000\n",
      "   macro avg       0.26      0.34      0.28      1000\n",
      "weighted avg       0.40      0.61      0.48      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import AllKNN\n",
    "\n",
    "aknn = AllKNN()\n",
    "\n",
    "for item, (X_train, X_test) in embed.items():\n",
    "    print(item)\n",
    "    X_resampled, y_resampled = aknn.fit_resample(X_train, y)\n",
    "    fit_test_OR(X_resampled, pd.Series(y_resampled), X_test, y_dev, y_codes, bin_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        80\n",
      "           1       1.00      0.00      0.01       302\n",
      "           2       0.62      1.00      0.76       618\n",
      "\n",
      "    accuracy                           0.62      1000\n",
      "   macro avg       0.54      0.33      0.26      1000\n",
      "weighted avg       0.68      0.62      0.47      1000\n",
      "\n",
      "text only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        80\n",
      "           1       0.57      0.03      0.05       302\n",
      "           2       0.62      0.99      0.76       618\n",
      "\n",
      "    accuracy                           0.62      1000\n",
      "   macro avg       0.40      0.34      0.27      1000\n",
      "weighted avg       0.56      0.62      0.49      1000\n",
      "\n",
      "concatenated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        80\n",
      "           1       0.57      0.04      0.07       302\n",
      "           2       0.62      0.99      0.76       618\n",
      "\n",
      "    accuracy                           0.62      1000\n",
      "   macro avg       0.40      0.34      0.28      1000\n",
      "weighted avg       0.56      0.62      0.49      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import OneSidedSelection\n",
    "\n",
    "oss = OneSidedSelection()\n",
    "\n",
    "for item, (X_train, X_test) in embed.items():\n",
    "    print(item)\n",
    "    X_resampled, y_resampled = oss.fit_resample(X_train, y)\n",
    "    fit_test_OR(X_resampled, pd.Series(y_resampled), X_test, y_dev, y_codes, bin_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        80\n",
      "           1       0.00      0.00      0.00       302\n",
      "           2       0.62      1.00      0.76       618\n",
      "\n",
      "    accuracy                           0.62      1000\n",
      "   macro avg       0.21      0.33      0.25      1000\n",
      "weighted avg       0.38      0.62      0.47      1000\n",
      "\n",
      "text only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        80\n",
      "           1       0.50      0.01      0.01       302\n",
      "           2       0.62      1.00      0.77       618\n",
      "\n",
      "    accuracy                           0.62      1000\n",
      "   macro avg       0.37      0.34      0.26      1000\n",
      "weighted avg       0.53      0.62      0.48      1000\n",
      "\n",
      "concatenated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.02        80\n",
      "           1       1.00      0.00      0.01       302\n",
      "           2       0.62      1.00      0.76       618\n",
      "\n",
      "    accuracy                           0.62      1000\n",
      "   macro avg       0.87      0.34      0.27      1000\n",
      "weighted avg       0.76      0.62      0.48      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
    "\n",
    "ncr = NeighbourhoodCleaningRule()\n",
    "\n",
    "for item, (X_train, X_test) in embed.items():\n",
    "    print(item)\n",
    "    X_resampled, y_resampled = ncr.fit_resample(X_train, y)\n",
    "    fit_test_OR(X_resampled, pd.Series(y_resampled), X_test, y_dev, y_codes, bin_clf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
