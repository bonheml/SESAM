{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 8 of Semeval 2020: Memotion analysis\n",
    "## Models training and evaluation\n",
    "This task is divided into 3 subtasks which are detailed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from joblib import dump, load\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from src.models.ordinal_regression import OrdinalClassifier\n",
    "from src.utils.files import load_dfs\n",
    "from src.utils.embeddings import retrieve_all_embeds\n",
    "from src.utils.reports import generate_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"data/models/custom\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(clf, embeds, y_train, y_dev, filename, multitask=False):\n",
    "    res = {}\n",
    "    for item, (X_train, X_dev, X_test) in embeds.items():\n",
    "        jobfile = \"{}/{}_{}.joblib\".format(model_path, filename, \"_\".join(item.split()))\n",
    "        print(\"############### Embeddings: {} ####################\".format(item))\n",
    "        if type(clf) == str:\n",
    "            load(jobfile)\n",
    "        else:\n",
    "            clf.fit(X_train, y_train)\n",
    "            dump(clf, jobfile) \n",
    "        y_pred_dev = clf.predict(X_dev)\n",
    "        y_pred_test = clf.predict(X_test)\n",
    "        if not multitask:\n",
    "            rep = classification_report(y_dev, y_pred_dev)\n",
    "            print(rep)\n",
    "        else:\n",
    "            rep = [classification_report(y_dev[:,col], y_pred_dev[:,col]) for col in range(y_dev.shape[1])]\n",
    "            cols = [\"Humour\", \"Sarcasm\", \"Offense\", \"Motivation\"]\n",
    "            for c, r in list(zip(cols, rep)):\n",
    "                print(\"results for class {}:\\n{}\".format(c, r))\n",
    "        res[item] = {\"pred_cls_dev\": y_pred_dev, \"report_str\": rep, \"pred_cls_test\": y_pred_test}\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_train, df_dev = load_dfs([\"data/train_cleaned_final.csv\", \"data/dev_cleaned_final.csv\"])\n",
    "embed = retrieve_all_embeds([(\"data/features/use.pkl.train\", \"data/features/xception.pkl.train\"), \n",
    "                             (\"data/features/use.pkl.dev\",\"data/features/xception.pkl.dev\"),\n",
    "                             (\"data/features/use.pkl.test\", \"data/features/xception.pkl.test\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A: sentiment polarity detection\n",
    "Classify memes as negative, neutral or positive. More details here: https://competitions.codalab.org/competitions/20629\n",
    "We compare the results of Ordinal classifier with logistic regression, SVM and random forest.\n",
    "To investigate how each modality contributes to the detection, we test these models with embeddings of sentences only, \n",
    "images only and both concatenated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_train_a = df_train[\"Overall_sentiment\"].cat.codes\n",
    "y_dev_a = df_dev[\"Overall_sentiment\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2\n",
       "1      0\n",
       "2      1\n",
       "3      2\n",
       "4      1\n",
       "      ..\n",
       "995    2\n",
       "996    2\n",
       "997    2\n",
       "998    2\n",
       "999    2\n",
       "Length: 1000, dtype: int8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dev_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Embeddings: image only ####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        80\n",
      "           1       0.00      0.00      0.00       302\n",
      "           2       0.62      1.00      0.76       618\n",
      "\n",
      "    accuracy                           0.62      1000\n",
      "   macro avg       0.21      0.33      0.25      1000\n",
      "weighted avg       0.38      0.62      0.47      1000\n",
      "\n",
      "############### Embeddings: text only ####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        80\n",
      "           1       0.00      0.00      0.00       302\n",
      "           2       0.62      1.00      0.76       618\n",
      "\n",
      "    accuracy                           0.62      1000\n",
      "   macro avg       0.21      0.33      0.25      1000\n",
      "weighted avg       0.38      0.62      0.47      1000\n",
      "\n",
      "############### Embeddings: concatenated ####################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        80\n",
      "           1       0.00      0.00      0.00       302\n",
      "           2       0.62      1.00      0.76       618\n",
      "\n",
      "    accuracy                           0.62      1000\n",
      "   macro avg       0.21      0.33      0.25      1000\n",
      "weighted avg       0.38      0.62      0.47      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "lr_oc = OrdinalClassifier(LogisticRegressionCV(cv=5, random_state=0, solver=\"saga\", max_iter=10000, n_jobs=6))\n",
    "res_a_lr = evaluate(lr_oc, embed, y_train_a, y_dev_a, \"task_a_lr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Embeddings: image only ####################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.03      0.03        80\n",
      "           1       0.30      0.30      0.30       302\n",
      "           2       0.61      0.64      0.63       618\n",
      "\n",
      "    accuracy                           0.49      1000\n",
      "   macro avg       0.32      0.32      0.32      1000\n",
      "weighted avg       0.47      0.49      0.48      1000\n",
      "\n",
      "############### Embeddings: text only ####################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.16      0.19        80\n",
      "           1       0.47      0.40      0.43       302\n",
      "           2       0.70      0.77      0.73       618\n",
      "\n",
      "    accuracy                           0.61      1000\n",
      "   macro avg       0.47      0.45      0.45      1000\n",
      "weighted avg       0.59      0.61      0.60      1000\n",
      "\n",
      "############### Embeddings: concatenated ####################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.23      0.24        80\n",
      "           1       0.49      0.42      0.45       302\n",
      "           2       0.71      0.77      0.74       618\n",
      "\n",
      "    accuracy                           0.62      1000\n",
      "   macro avg       0.48      0.47      0.47      1000\n",
      "weighted avg       0.61      0.62      0.61      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_oc = OrdinalClassifier(KNeighborsClassifier(n_jobs=6))\n",
    "res_a_knn = evaluate(knn_oc, embed, y_train_a, y_dev_a, \"task_a_knn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Embeddings: image only ####################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.65      0.14        80\n",
      "           1       0.27      0.15      0.19       302\n",
      "           2       0.62      0.16      0.26       618\n",
      "\n",
      "    accuracy                           0.20      1000\n",
      "   macro avg       0.32      0.32      0.20      1000\n",
      "weighted avg       0.47      0.20      0.23      1000\n",
      "\n",
      "############### Embeddings: text only ####################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.14      0.15        80\n",
      "           1       0.40      0.23      0.29       302\n",
      "           2       0.65      0.80      0.72       618\n",
      "\n",
      "    accuracy                           0.58      1000\n",
      "   macro avg       0.41      0.39      0.39      1000\n",
      "weighted avg       0.54      0.58      0.54      1000\n",
      "\n",
      "############### Embeddings: concatenated ####################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.65      0.14        80\n",
      "           1       0.27      0.15      0.19       302\n",
      "           2       0.62      0.16      0.26       618\n",
      "\n",
      "    accuracy                           0.20      1000\n",
      "   macro avg       0.32      0.32      0.20      1000\n",
      "weighted avg       0.47      0.20      0.23      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gnb_oc = OrdinalClassifier(GaussianNB())\n",
    "res_a_gnb = evaluate(gnb_oc, embed, y_train_a, y_dev_a, \"task_a_gnb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Embeddings: image only ####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.03      0.04        80\n",
      "           1       0.00      0.00      0.00       302\n",
      "           2       0.62      0.98      0.76       618\n",
      "\n",
      "    accuracy                           0.61      1000\n",
      "   macro avg       0.24      0.34      0.27      1000\n",
      "weighted avg       0.39      0.61      0.47      1000\n",
      "\n",
      "############### Embeddings: text only ####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.10      0.17        80\n",
      "           1       0.00      0.00      0.00       302\n",
      "           2       0.63      1.00      0.77       618\n",
      "\n",
      "    accuracy                           0.62      1000\n",
      "   macro avg       0.40      0.37      0.31      1000\n",
      "weighted avg       0.43      0.62      0.49      1000\n",
      "\n",
      "############### Embeddings: concatenated ####################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.05      0.09        80\n",
      "           1       0.00      0.00      0.00       302\n",
      "           2       0.62      1.00      0.77       618\n",
      "\n",
      "    accuracy                           0.62      1000\n",
      "   macro avg       0.33      0.35      0.28      1000\n",
      "weighted avg       0.41      0.62      0.48      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "abc_oc = OrdinalClassifier(AdaBoostClassifier(n_estimators=100, random_state=0))\n",
    "res_a_abc = evaluate(abc_oc, embed, y_train_a, y_dev_a, \"task_a_abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Embeddings: image only ####################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.07      0.07        80\n",
      "           1       0.30      0.25      0.27       302\n",
      "           2       0.63      0.68      0.65       618\n",
      "\n",
      "    accuracy                           0.50      1000\n",
      "   macro avg       0.33      0.33      0.33      1000\n",
      "weighted avg       0.48      0.50      0.49      1000\n",
      "\n",
      "############### Embeddings: text only ####################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.76      0.85        80\n",
      "           1       0.98      0.76      0.86       302\n",
      "           2       0.87      0.99      0.93       618\n",
      "\n",
      "    accuracy                           0.90      1000\n",
      "   macro avg       0.93      0.84      0.88      1000\n",
      "weighted avg       0.91      0.90      0.90      1000\n",
      "\n",
      "############### Embeddings: concatenated ####################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.03      0.05        80\n",
      "           1       0.73      0.08      0.14       302\n",
      "           2       0.63      0.99      0.77       618\n",
      "\n",
      "    accuracy                           0.64      1000\n",
      "   macro avg       0.68      0.36      0.32      1000\n",
      "weighted avg       0.66      0.64      0.52      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_oc = OrdinalClassifier(RandomForestClassifier(random_state=0, oob_score=True, n_jobs=6))\n",
    "res_a_rf = evaluate(rf_oc, embed, y_train_a, y_dev_a, \"task_a_rf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Embeddings: image only ####################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.09      0.09        80\n",
      "           1       0.29      0.27      0.28       302\n",
      "           2       0.62      0.64      0.63       618\n",
      "\n",
      "    accuracy                           0.48      1000\n",
      "   macro avg       0.33      0.33      0.33      1000\n",
      "weighted avg       0.48      0.48      0.48      1000\n",
      "\n",
      "############### Embeddings: text only ####################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.76      0.84        80\n",
      "           1       0.83      0.82      0.82       302\n",
      "           2       0.90      0.92      0.91       618\n",
      "\n",
      "    accuracy                           0.88      1000\n",
      "   macro avg       0.88      0.83      0.86      1000\n",
      "weighted avg       0.88      0.88      0.88      1000\n",
      "\n",
      "############### Embeddings: concatenated ####################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.55      0.66        80\n",
      "           1       0.67      0.70      0.68       302\n",
      "           2       0.84      0.85      0.85       618\n",
      "\n",
      "    accuracy                           0.78      1000\n",
      "   macro avg       0.77      0.70      0.73      1000\n",
      "weighted avg       0.79      0.78      0.78      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp_oc = OrdinalClassifier(MLPClassifier(max_iter=1000))\n",
    "res_a_mlp = evaluate(mlp_oc, embed, y_train_a, y_dev_a, \"task_a_mlp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task B: Multilabel sentiment detection\n",
    "Classify memes as Humourous, sarcastics, offensive and/or motivationnal. One meme can have multiple sentiments.\n",
    "More details here: https://competitions.codalab.org/competitions/20629\n",
    "We compare the results of OneVsRest classifier with logistic regression, SVM and random forest.\n",
    "To investigate how each modality contributes to the detection, we test these models with embeddings of sentences only, \n",
    "images only and both concatenated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_b = df_train[[\"Humour_bin\", \"Sarcasm_bin\", \"Offense_bin\", \"Motivation_bin\"]].to_numpy().astype(int)\n",
    "y_dev_b = df_dev[[\"Humour_bin\", \"Sarcasm_bin\", \"Offense_bin\", \"Motivation_bin\"]].to_numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 0],\n",
       "       [1, 1, 0, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, 0],\n",
       "       [1, 1, 1, 0],\n",
       "       [1, 1, 1, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dev_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Embeddings: image only ####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87       773\n",
      "           1       0.75      1.00      0.86       751\n",
      "           2       0.60      1.00      0.75       601\n",
      "           3       0.00      0.00      0.00       366\n",
      "\n",
      "   micro avg       0.71      0.85      0.77      2491\n",
      "   macro avg       0.53      0.75      0.62      2491\n",
      "weighted avg       0.61      0.85      0.71      2491\n",
      " samples avg       0.71      0.80      0.72      2491\n",
      "\n",
      "############### Embeddings: text only ####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87       773\n",
      "           1       0.75      1.00      0.86       751\n",
      "           2       0.60      1.00      0.75       601\n",
      "           3       0.00      0.00      0.00       366\n",
      "\n",
      "   micro avg       0.71      0.85      0.77      2491\n",
      "   macro avg       0.53      0.75      0.62      2491\n",
      "weighted avg       0.61      0.85      0.71      2491\n",
      " samples avg       0.71      0.80      0.72      2491\n",
      "\n",
      "############### Embeddings: concatenated ####################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87       773\n",
      "           1       0.75      1.00      0.86       751\n",
      "           2       0.60      1.00      0.75       601\n",
      "           3       0.00      0.00      0.00       366\n",
      "\n",
      "   micro avg       0.71      0.85      0.77      2491\n",
      "   macro avg       0.53      0.75      0.62      2491\n",
      "weighted avg       0.61      0.85      0.71      2491\n",
      " samples avg       0.71      0.80      0.72      2491\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "lr_ovc = OneVsRestClassifier(LogisticRegressionCV(cv=5, random_state=0, solver=\"saga\", max_iter=10000, n_jobs=6))\n",
    "res_b_lr = evaluate(lr_ovc, embed, y_train_b, y_dev_b, \"task_b_lr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Embeddings: image only ####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.90      0.83       773\n",
      "           1       0.76      0.93      0.84       751\n",
      "           2       0.62      0.70      0.66       601\n",
      "           3       0.32      0.22      0.26       366\n",
      "\n",
      "   micro avg       0.69      0.76      0.72      2491\n",
      "   macro avg       0.62      0.69      0.65      2491\n",
      "weighted avg       0.66      0.76      0.71      2491\n",
      " samples avg       0.69      0.71      0.66      2491\n",
      "\n",
      "############### Embeddings: text only ####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.86       773\n",
      "           1       0.78      0.96      0.86       751\n",
      "           2       0.69      0.80      0.74       601\n",
      "           3       0.56      0.34      0.43       366\n",
      "\n",
      "   micro avg       0.74      0.83      0.78      2491\n",
      "   macro avg       0.71      0.76      0.72      2491\n",
      "weighted avg       0.73      0.83      0.77      2491\n",
      " samples avg       0.74      0.78      0.72      2491\n",
      "\n",
      "############### Embeddings: concatenated ####################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.87       773\n",
      "           1       0.78      0.97      0.87       751\n",
      "           2       0.69      0.82      0.75       601\n",
      "           3       0.58      0.34      0.43       366\n",
      "\n",
      "   micro avg       0.75      0.84      0.79      2491\n",
      "   macro avg       0.71      0.77      0.73      2491\n",
      "weighted avg       0.74      0.84      0.78      2491\n",
      " samples avg       0.74      0.79      0.73      2491\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "knn_ovc = OneVsRestClassifier(KNeighborsClassifier(n_jobs=6))\n",
    "res_b_knn = evaluate(knn_ovc, embed, y_train_b, y_dev_b, \"task_b_knn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Embeddings: image only ####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.23      0.36       773\n",
      "           1       0.73      0.24      0.36       751\n",
      "           2       0.61      0.19      0.29       601\n",
      "           3       0.38      0.80      0.51       366\n",
      "\n",
      "   micro avg       0.53      0.31      0.39      2491\n",
      "   macro avg       0.63      0.37      0.38      2491\n",
      "weighted avg       0.67      0.31      0.37      2491\n",
      " samples avg       0.45      0.28      0.31      2491\n",
      "\n",
      "############### Embeddings: text only ####################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82       773\n",
      "           1       0.77      0.80      0.79       751\n",
      "           2       0.66      0.66      0.66       601\n",
      "           3       0.44      0.41      0.42       366\n",
      "\n",
      "   micro avg       0.71      0.73      0.72      2491\n",
      "   macro avg       0.66      0.68      0.67      2491\n",
      "weighted avg       0.70      0.73      0.71      2491\n",
      " samples avg       0.68      0.68      0.64      2491\n",
      "\n",
      "############### Embeddings: concatenated ####################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.24      0.36       773\n",
      "           1       0.73      0.24      0.36       751\n",
      "           2       0.61      0.19      0.30       601\n",
      "           3       0.38      0.80      0.51       366\n",
      "\n",
      "   micro avg       0.54      0.31      0.39      2491\n",
      "   macro avg       0.63      0.37      0.38      2491\n",
      "weighted avg       0.67      0.31      0.37      2491\n",
      " samples avg       0.45      0.28      0.31      2491\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "gnb_ovc = OneVsRestClassifier(GaussianNB())\n",
    "res_b_gnb = evaluate(gnb_ovc, embed, y_train_b, y_dev_b, \"task_b_gnb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Embeddings: image only ####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.95      0.85       773\n",
      "           1       0.75      0.97      0.84       751\n",
      "           2       0.60      0.80      0.69       601\n",
      "           3       0.32      0.11      0.17       366\n",
      "\n",
      "   micro avg       0.70      0.80      0.74      2491\n",
      "   macro avg       0.61      0.71      0.64      2491\n",
      "weighted avg       0.66      0.80      0.71      2491\n",
      " samples avg       0.70      0.75      0.69      2491\n",
      "\n",
      "############### Embeddings: text only ####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.96      0.87       773\n",
      "           1       0.77      0.97      0.86       751\n",
      "           2       0.66      0.87      0.75       601\n",
      "           3       0.60      0.28      0.39       366\n",
      "\n",
      "   micro avg       0.74      0.84      0.79      2491\n",
      "   macro avg       0.71      0.77      0.72      2491\n",
      "weighted avg       0.73      0.84      0.77      2491\n",
      " samples avg       0.73      0.79      0.72      2491\n",
      "\n",
      "############### Embeddings: concatenated ####################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.95      0.86       773\n",
      "           1       0.76      0.96      0.85       751\n",
      "           2       0.65      0.83      0.72       601\n",
      "           3       0.49      0.25      0.34       366\n",
      "\n",
      "   micro avg       0.72      0.82      0.77      2491\n",
      "   macro avg       0.67      0.75      0.69      2491\n",
      "weighted avg       0.70      0.82      0.75      2491\n",
      " samples avg       0.72      0.77      0.71      2491\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "abc_ovc = OneVsRestClassifier(AdaBoostClassifier(n_estimators=100, random_state=0))\n",
    "res_b_abc = evaluate(abc_ovc, embed, y_train_b, y_dev_b, \"task_b_abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Embeddings: image only ####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78       773\n",
      "           1       0.76      0.85      0.80       751\n",
      "           2       0.61      0.68      0.64       601\n",
      "           3       0.37      0.30      0.33       366\n",
      "\n",
      "   micro avg       0.68      0.71      0.69      2491\n",
      "   macro avg       0.62      0.66      0.64      2491\n",
      "weighted avg       0.67      0.71      0.69      2491\n",
      " samples avg       0.65      0.67      0.61      2491\n",
      "\n",
      "############### Embeddings: text only ####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       773\n",
      "           1       0.93      0.99      0.96       751\n",
      "           2       0.87      0.98      0.92       601\n",
      "           3       0.98      0.80      0.88       366\n",
      "\n",
      "   micro avg       0.92      0.96      0.94      2491\n",
      "   macro avg       0.93      0.94      0.93      2491\n",
      "weighted avg       0.93      0.96      0.94      2491\n",
      " samples avg       0.87      0.89      0.87      2491\n",
      "\n",
      "############### Embeddings: concatenated ####################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87       773\n",
      "           1       0.75      1.00      0.86       751\n",
      "           2       0.63      0.94      0.75       601\n",
      "           3       0.68      0.08      0.14       366\n",
      "\n",
      "   micro avg       0.72      0.85      0.78      2491\n",
      "   macro avg       0.71      0.75      0.66      2491\n",
      "weighted avg       0.72      0.85      0.73      2491\n",
      " samples avg       0.72      0.80      0.73      2491\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "rf_ovc = OneVsRestClassifier(RandomForestClassifier(random_state=0,oob_score=True, n_jobs=6))\n",
    "res_b_rf = evaluate(rf_ovc, embed, y_train_b, y_dev_b, \"task_b_rf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Embeddings: image only ####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78       773\n",
      "           1       0.76      0.84      0.80       751\n",
      "           2       0.61      0.70      0.65       601\n",
      "           3       0.37      0.31      0.33       366\n",
      "\n",
      "   micro avg       0.68      0.71      0.69      2491\n",
      "   macro avg       0.63      0.66      0.64      2491\n",
      "weighted avg       0.67      0.71      0.69      2491\n",
      " samples avg       0.65      0.67      0.62      2491\n",
      "\n",
      "############### Embeddings: text only ####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       773\n",
      "           1       0.93      0.97      0.95       751\n",
      "           2       0.90      0.91      0.90       601\n",
      "           3       0.87      0.84      0.86       366\n",
      "\n",
      "   micro avg       0.92      0.93      0.93      2491\n",
      "   macro avg       0.91      0.92      0.92      2491\n",
      "weighted avg       0.92      0.93      0.93      2491\n",
      " samples avg       0.86      0.87      0.85      2491\n",
      "\n",
      "############### Embeddings: concatenated ####################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91       773\n",
      "           1       0.88      0.94      0.91       751\n",
      "           2       0.83      0.84      0.83       601\n",
      "           3       0.74      0.72      0.73       366\n",
      "\n",
      "   micro avg       0.85      0.88      0.86      2491\n",
      "   macro avg       0.83      0.86      0.84      2491\n",
      "weighted avg       0.85      0.88      0.86      2491\n",
      " samples avg       0.81      0.81      0.79      2491\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "mlp_ovc = OneVsRestClassifier(MLPClassifier(max_iter=1000))\n",
    "res_b_mlp = evaluate(mlp_ovc, embed, y_train_b, y_dev_b, \"task_b_mlp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task C: Multilabel sentiment intensity detection\n",
    "Classify the degree of humour, sarcasm, offense and motivation of each meme. \n",
    "One meme can have multiple sentiments of different intensities. Each sentiment intensity is ranked from 0 (not at all) \n",
    "to 5 (very much).\n",
    "More details here: https://competitions.codalab.org/competitions/20629\n",
    "We compare the results of OneVsRest Ordinal classifier with logistic regression, SVM and random forest.\n",
    "To investigate how each modality contributes to the detection, we test these models with embeddings of sentences only, \n",
    "images only and both concatenated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"Humour\", \"Sarcasm\", \"Offense\", \"Motivation\"]\n",
    "y_train_c = pd.concat([df_train[name].cat.codes for name in cols], axis=1).to_numpy()\n",
    "y_dev_c = pd.concat([df_dev[name].cat.codes for name in cols], axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 3, 0],\n",
       "       [1, 1, 0, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 2, 0],\n",
       "       [2, 2, 2, 0],\n",
       "       [1, 1, 1, 0]], dtype=int8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dev_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Embeddings: image only ####################\n"
     ]
    }
   ],
   "source": [
    "lr_ovc_oc = MultiOutputClassifier(OrdinalClassifier(LogisticRegressionCV(cv=5, random_state=0, solver=\"saga\", max_iter=10000, n_jobs=6)))\n",
    "res_c_lr = evaluate(lr_ovc_oc, embed, y_train_c, y_dev_c, \"task_c_lr\", multitask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_a = res_a_lr[\"text only\"][\"pred_cls_test\"]\n",
    "task_b = res_b_lr[\"text only\"][\"pred_cls_test\"]\n",
    "task_c = res_c_lr[\"text only\"][\"pred_cls_test\"]\n",
    "r = generate_report(task_a, task_b, task_c, zipname=\"res_lr.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "knn_ovc_oc = MultiOutputClassifier(OrdinalClassifier(KNeighborsClassifier(n_jobs=6)))\n",
    "res_c_knn = evaluate(knn_ovc_oc, embed, y_train_c, y_dev_c, \"task_c_knn\", multitask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_a = res_a_knn[\"text only\"][\"pred_cls_test\"]\n",
    "task_b = res_b_knn[\"text only\"][\"pred_cls_test\"]\n",
    "task_c = res_c_knn[\"text only\"][\"pred_cls_test\"]\n",
    "r = generate_report(task_a, task_b, task_c, zipname=\"res_knn.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_a = res_a_knn[\"concatenated\"][\"pred_cls_test\"]\n",
    "task_b = res_b_knn[\"concatenated\"][\"pred_cls_test\"]\n",
    "task_c = res_c_knn[\"concatenated\"][\"pred_cls_test\"]\n",
    "r = generate_report(task_a, task_b, task_c, zipname=\"res_knn_concat.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gnb_ovc_oc = MultiOutputClassifier(OrdinalClassifier(GaussianNB()))\n",
    "res_c_gnb = evaluate(gnb_ovc_oc, embed, y_train_c, y_dev_c, \"task_c_gnb\", multitask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_a = res_a_gnb[\"text only\"][\"pred_cls_test\"]\n",
    "task_b = res_b_gnb[\"text only\"][\"pred_cls_test\"]\n",
    "task_c = res_c_gnb[\"text only\"][\"pred_cls_test\"]\n",
    "r = generate_report(task_a, task_b, task_c, zipname=\"res_gnb.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "abc_ovc_oc = MultiOutputClassifier(OrdinalClassifier(AdaBoostClassifier(n_estimators=100, random_state=0)))\n",
    "res_c_abc = evaluate(abc_ovc_oc, embed, y_train_c, y_dev_c, \"task_c_abc\", multitask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_a = res_a_abc[\"text only\"][\"pred_cls_test\"]\n",
    "task_b = res_b_abc[\"text only\"][\"pred_cls_test\"]\n",
    "task_c = res_c_abc[\"text only\"][\"pred_cls_test\"]\n",
    "r = generate_report(task_a, task_b, task_c, zipname=\"res_abc.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rf_ovc_oc = MultiOutputClassifier(OrdinalClassifier(RandomForestClassifier(random_state=0, oob_score=True, n_jobs=6)))\n",
    "res_c_rf = evaluate(rf_ovc_oc, embed, y_train_c, y_dev_c, \"task_c_rf\", multitask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_a = res_a_rf[\"text only\"][\"pred_cls_test\"]\n",
    "task_b = res_b_rf[\"text only\"][\"pred_cls_test\"]\n",
    "task_c = res_c_rf[\"text only\"][\"pred_cls_test\"]\n",
    "r = generate_report(task_a, task_b, task_c, zipname=\"res_rf.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mlp_ovc_oc = MultiOutputClassifier(OrdinalClassifier(MLPClassifier(max_iter=1000)))\n",
    "res_c_mlp = evaluate(mlp_ovc_oc, embed, y_train_c, y_dev_c, \"task_c_mlp\", multitask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_a = res_a_mlp[\"text only\"][\"pred_cls_test\"]\n",
    "task_b = res_b_mlp[\"text only\"][\"pred_cls_test\"]\n",
    "task_c = res_c_mlp[\"text only\"][\"pred_cls_test\"]\n",
    "r = generate_report(task_a, task_b, task_c, zipname=\"res_mlp.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_a = res_a_mlp[\"concatenated\"][\"pred_cls_test\"]\n",
    "task_b = res_b_mlp[\"concatenated\"][\"pred_cls_test\"]\n",
    "task_c = res_c_mlp[\"concatenated\"][\"pred_cls_test\"]\n",
    "r = generate_report(task_a, task_b, task_c, zipname=\"res_mlp_concat.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating report\n",
    "We take the results of the best classifier for each task, here the random forest and generate a report following the guidelines provided here: https://competitions.codalab.org/competitions/20629#learn_the_details-submission-guidelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_a = res_a_rf[\"text only\"][\"pred_cls_test\"]\n",
    "task_b = res_b_rf[\"text only\"][\"pred_cls_test\"]\n",
    "task_c = res_c_rf[\"text only\"][\"pred_cls_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = generate_report(task_a, task_b, task_c, zipname=\"res_rf.zip\")\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
