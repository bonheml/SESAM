{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 8 of Semeval 2020: Memotion analysis\n",
    "## Models training and evaluation\n",
    "This task is divided into 3 subtasks which are detailed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from src.models.ordinal_regression import OrdinalClassifier\n",
    "from src.utils.files import load_dfs\n",
    "from src.utils.embeddings import retrieve_all_embeds\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(clf, embeds, y_train, y_dev, multitask=False):\n",
    "    res = {}\n",
    "    for item, (X_train, X_dev, X_test) in embeds.items():\n",
    "            print(\"############### Embeddings: {} ####################\".format(item))\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred_dev = clf.predict(X_dev)\n",
    "            y_pred_test = clf.predict(X_test)\n",
    "            if not multitask:\n",
    "                rep = classification_report(y_dev, y_pred_dev)\n",
    "                print(rep)\n",
    "            else:\n",
    "                rep = [classification_report(y_dev[:,col], y_pred_dev[:,col]) for col in range(y_dev.shape[1])]\n",
    "                cols = [\"Humour\", \"Sarcasm\", \"Offense\", \"Motivation\"]\n",
    "                for c, r in list(zip(cols, rep)):\n",
    "                    print(\"results for class {}:\\n{}\".format(c, r))\n",
    "            res[item] = {\"pred_cls_dev\": y_pred_dev, \"report_str\": rep, \"pred_cls_test\": y_pred_test}\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_train, df_dev = load_dfs([\"data/train_cleaned_final.csv\", \"data/dev_cleaned_final.csv\"])\n",
    "embed = retrieve_all_embeds([(\"data/features/use.pkl.train\", \"data/features/xception.pkl.train\"), \n",
    "                              (\"data/features/use.pkl.dev\",\"data/features/xception.pkl.dev\"),\n",
    "                              (\"data/features/use.pkl.test\", \"data/features/xception.pkl.test\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A: sentiment polarity detection\n",
    "Classify memes as negative, neutral or positive. More details here: https://competitions.codalab.org/competitions/20629\n",
    "We compare the results of Ordinal classifier with logistic regression, SVM and random forest.\n",
    "To investigate how each modality contributes to the detection, we test these models with embeddings of sentences only, \n",
    "images only and both concatenated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_train_a = df_train[\"Overall_sentiment\"].cat.codes\n",
    "y_dev_a = df_dev[\"Overall_sentiment\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2\n",
       "1      0\n",
       "2      1\n",
       "3      2\n",
       "4      1\n",
       "      ..\n",
       "995    2\n",
       "996    2\n",
       "997    2\n",
       "998    2\n",
       "999    2\n",
       "Length: 1000, dtype: int8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dev_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image only\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        80\n",
      "           1       1.00      0.00      0.01       302\n",
      "           2       0.62      1.00      0.76       618\n",
      "\n",
      "    accuracy                           0.62      1000\n",
      "   macro avg       0.54      0.33      0.26      1000\n",
      "weighted avg       0.68      0.62      0.47      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text only\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        80\n",
      "           1       0.60      0.04      0.07       302\n",
      "           2       0.62      0.99      0.76       618\n",
      "\n",
      "    accuracy                           0.62      1000\n",
      "   macro avg       0.41      0.34      0.28      1000\n",
      "weighted avg       0.57      0.62      0.50      1000\n",
      "\n",
      "concatenated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        80\n",
      "           1       0.55      0.06      0.11       302\n",
      "           2       0.63      0.98      0.76       618\n",
      "\n",
      "    accuracy                           0.62      1000\n",
      "   macro avg       0.39      0.35      0.29      1000\n",
      "weighted avg       0.55      0.62      0.51      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "lr_oc = OrdinalClassifier(LogisticRegression(random_state=0, solver=\"lbfgs\"))\n",
    "res_a_lr = evaluate(lr_oc, embed, y_train_a, y_dev_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image only\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        80\n",
      "           1       0.00      0.00      0.00       302\n",
      "           2       0.62      1.00      0.76       618\n",
      "\n",
      "    accuracy                           0.62      1000\n",
      "   macro avg       0.21      0.33      0.25      1000\n",
      "weighted avg       0.38      0.62      0.47      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text only\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        80\n",
      "           1       0.00      0.00      0.00       302\n",
      "           2       0.62      1.00      0.76       618\n",
      "\n",
      "    accuracy                           0.62      1000\n",
      "   macro avg       0.21      0.33      0.25      1000\n",
      "weighted avg       0.38      0.62      0.47      1000\n",
      "\n",
      "concatenated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        80\n",
      "           1       0.00      0.00      0.00       302\n",
      "           2       0.62      1.00      0.76       618\n",
      "\n",
      "    accuracy                           0.62      1000\n",
      "   macro avg       0.21      0.33      0.25      1000\n",
      "weighted avg       0.38      0.62      0.47      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "svm_oc = OrdinalClassifier(SVC(probability=True))\n",
    "res_a_svc = evaluate(svm_oc, embed, y_train_a, y_dev_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image only\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.07      0.07        80\n",
      "           1       0.30      0.25      0.27       302\n",
      "           2       0.63      0.68      0.65       618\n",
      "\n",
      "    accuracy                           0.50      1000\n",
      "   macro avg       0.33      0.33      0.33      1000\n",
      "weighted avg       0.48      0.50      0.49      1000\n",
      "\n",
      "text only\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.76      0.85        80\n",
      "           1       0.98      0.76      0.86       302\n",
      "           2       0.87      0.99      0.93       618\n",
      "\n",
      "    accuracy                           0.90      1000\n",
      "   macro avg       0.93      0.84      0.88      1000\n",
      "weighted avg       0.91      0.90      0.90      1000\n",
      "\n",
      "concatenated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.03      0.05        80\n",
      "           1       0.73      0.08      0.14       302\n",
      "           2       0.63      0.99      0.77       618\n",
      "\n",
      "    accuracy                           0.64      1000\n",
      "   macro avg       0.68      0.36      0.32      1000\n",
      "weighted avg       0.66      0.64      0.52      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_oc = OrdinalClassifier(RandomForestClassifier(random_state=0))\n",
    "res_a_rf = evaluate(rf_oc, embed, y_train_a, y_dev_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task B: Multilabel sentiment detection\n",
    "Classify memes as Humourous, sarcastics, offensive and/or motivationnal. One meme can have multiple sentiments.\n",
    "More details here: https://competitions.codalab.org/competitions/20629\n",
    "We compare the results of OneVsRest classifier with logistic regression, SVM and random forest.\n",
    "To investigate how each modality contributes to the detection, we test these models with embeddings of sentences only, \n",
    "images only and both concatenated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_b = df_train[[\"Humour_bin\", \"Sarcasm_bin\", \"Offense_bin\", \"Motivation_bin\"]].to_numpy().astype(int)\n",
    "y_dev_b = df_dev[[\"Humour_bin\", \"Sarcasm_bin\", \"Offense_bin\", \"Motivation_bin\"]].to_numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 0],\n",
       "       [1, 1, 0, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, 0],\n",
       "       [1, 1, 1, 0],\n",
       "       [1, 1, 1, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dev_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image only\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87       773\n",
      "           1       0.75      1.00      0.86       751\n",
      "           2       0.60      1.00      0.75       601\n",
      "           3       0.00      0.00      0.00       366\n",
      "\n",
      "   micro avg       0.71      0.85      0.77      2491\n",
      "   macro avg       0.53      0.75      0.62      2491\n",
      "weighted avg       0.61      0.85      0.71      2491\n",
      " samples avg       0.71      0.80      0.72      2491\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text only\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87       773\n",
      "           1       0.75      1.00      0.86       751\n",
      "           2       0.61      0.96      0.75       601\n",
      "           3       0.57      0.07      0.12       366\n",
      "\n",
      "   micro avg       0.71      0.85      0.78      2491\n",
      "   macro avg       0.68      0.76      0.65      2491\n",
      "weighted avg       0.70      0.85      0.73      2491\n",
      " samples avg       0.71      0.80      0.72      2491\n",
      "\n",
      "concatenated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87       773\n",
      "           1       0.75      1.00      0.86       751\n",
      "           2       0.62      0.94      0.75       601\n",
      "           3       0.56      0.07      0.13       366\n",
      "\n",
      "   micro avg       0.72      0.85      0.78      2491\n",
      "   macro avg       0.68      0.75      0.65      2491\n",
      "weighted avg       0.70      0.85      0.73      2491\n",
      " samples avg       0.72      0.80      0.72      2491\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "lr_ovc = OneVsRestClassifier(LogisticRegression(random_state=0, solver=\"lbfgs\"))\n",
    "res_b_lr = evaluate(lr_ovc, embed, y_train_b, y_dev_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image only\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.87       773\n",
      "           1       0.75      1.00      0.86       751\n",
      "           2       0.60      0.98      0.75       601\n",
      "           3       0.33      0.01      0.02       366\n",
      "\n",
      "   micro avg       0.71      0.85      0.77      2491\n",
      "   macro avg       0.62      0.75      0.62      2491\n",
      "weighted avg       0.66      0.85      0.71      2491\n",
      " samples avg       0.71      0.80      0.72      2491\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text only\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88       773\n",
      "           1       0.75      1.00      0.86       751\n",
      "           2       0.67      1.00      0.80       601\n",
      "           3       0.98      0.17      0.30       366\n",
      "\n",
      "   micro avg       0.74      0.88      0.80      2491\n",
      "   macro avg       0.80      0.79      0.71      2491\n",
      "weighted avg       0.78      0.88      0.77      2491\n",
      " samples avg       0.73      0.83      0.75      2491\n",
      "\n",
      "concatenated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87       773\n",
      "           1       0.75      1.00      0.86       751\n",
      "           2       0.63      1.00      0.77       601\n",
      "           3       1.00      0.03      0.06       366\n",
      "\n",
      "   micro avg       0.72      0.86      0.78      2491\n",
      "   macro avg       0.79      0.76      0.64      2491\n",
      "weighted avg       0.76      0.86      0.72      2491\n",
      " samples avg       0.72      0.81      0.73      2491\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "svm_ovc = OneVsRestClassifier(SVC(probability=True))\n",
    "res_b_svc = evaluate(svm_ovc, embed, y_train_b, y_dev_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image only\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78       773\n",
      "           1       0.76      0.85      0.80       751\n",
      "           2       0.61      0.68      0.64       601\n",
      "           3       0.37      0.30      0.33       366\n",
      "\n",
      "   micro avg       0.68      0.71      0.69      2491\n",
      "   macro avg       0.62      0.66      0.64      2491\n",
      "weighted avg       0.67      0.71      0.69      2491\n",
      " samples avg       0.65      0.67      0.61      2491\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text only\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       773\n",
      "           1       0.93      0.99      0.96       751\n",
      "           2       0.87      0.98      0.92       601\n",
      "           3       0.98      0.80      0.88       366\n",
      "\n",
      "   micro avg       0.92      0.96      0.94      2491\n",
      "   macro avg       0.93      0.94      0.93      2491\n",
      "weighted avg       0.93      0.96      0.94      2491\n",
      " samples avg       0.87      0.89      0.87      2491\n",
      "\n",
      "concatenated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87       773\n",
      "           1       0.75      1.00      0.86       751\n",
      "           2       0.63      0.94      0.75       601\n",
      "           3       0.68      0.08      0.14       366\n",
      "\n",
      "   micro avg       0.72      0.85      0.78      2491\n",
      "   macro avg       0.71      0.75      0.66      2491\n",
      "weighted avg       0.72      0.85      0.73      2491\n",
      " samples avg       0.72      0.80      0.73      2491\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "rf_ovc = OneVsRestClassifier(RandomForestClassifier(random_state=0))\n",
    "res_b_rf = evaluate(rf_ovc, embed, y_train_b, y_dev_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task C: Multilabel sentiment intensity detection\n",
    "Classify the degree of humour, sarcasm, offense and motivation of each meme. \n",
    "One meme can have multiple sentiments of different intensities. Each sentiment intensity is ranked from 0 (not at all) \n",
    "to 5 (very much).\n",
    "More details here: https://competitions.codalab.org/competitions/20629\n",
    "We compare the results of OneVsRest Ordinal classifier with logistic regression, SVM and random forest.\n",
    "To investigate how each modality contributes to the detection, we test these models with embeddings of sentences only, \n",
    "images only and both concatenated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"Humour\", \"Sarcasm\", \"Offense\", \"Motivation\"]\n",
    "y_train_c = pd.concat([df_train[name].cat.codes for name in cols], axis=1).to_numpy()\n",
    "y_dev_c = pd.concat([df_dev[name].cat.codes for name in cols], axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 3, 0],\n",
       "       [1, 1, 0, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 2, 0],\n",
       "       [2, 2, 2, 0],\n",
       "       [1, 1, 1, 0]], dtype=int8)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dev_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Embeddings: image only ####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for class Humour:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.02      0.03       227\n",
      "           1       0.35      0.76      0.48       343\n",
      "           2       0.33      0.23      0.27       341\n",
      "           3       0.00      0.00      0.00        89\n",
      "\n",
      "    accuracy                           0.34      1000\n",
      "   macro avg       0.24      0.25      0.19      1000\n",
      "weighted avg       0.30      0.34      0.26      1000\n",
      "\n",
      "results for class Sarcasm:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.01       249\n",
      "           1       0.49      1.00      0.66       491\n",
      "           2       0.00      0.00      0.00       214\n",
      "           3       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.49      1000\n",
      "   macro avg       0.37      0.25      0.17      1000\n",
      "weighted avg       0.49      0.49      0.33      1000\n",
      "\n",
      "results for class Offense:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.85      0.55       399\n",
      "           1       0.36      0.17      0.23       352\n",
      "           2       0.00      0.00      0.00       220\n",
      "           3       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.40      1000\n",
      "   macro avg       0.19      0.25      0.20      1000\n",
      "weighted avg       0.29      0.40      0.30      1000\n",
      "\n",
      "results for class Motivation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      1.00      0.78       634\n",
      "           1       0.00      0.00      0.00       366\n",
      "\n",
      "    accuracy                           0.63      1000\n",
      "   macro avg       0.32      0.50      0.39      1000\n",
      "weighted avg       0.40      0.63      0.49      1000\n",
      "\n",
      "############### Embeddings: text only ####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for class Humour:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.14      0.21       227\n",
      "           1       0.40      0.61      0.48       343\n",
      "           2       0.40      0.47      0.43       341\n",
      "           3       0.00      0.00      0.00        89\n",
      "\n",
      "    accuracy                           0.40      1000\n",
      "   macro avg       0.31      0.30      0.28      1000\n",
      "weighted avg       0.37      0.40      0.36      1000\n",
      "\n",
      "results for class Sarcasm:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.03      0.06       249\n",
      "           1       0.49      0.97      0.65       491\n",
      "           2       0.38      0.03      0.05       214\n",
      "           3       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.49      1000\n",
      "   macro avg       0.36      0.26      0.19      1000\n",
      "weighted avg       0.46      0.49      0.35      1000\n",
      "\n",
      "results for class Offense:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.60      0.52       399\n",
      "           1       0.43      0.57      0.49       352\n",
      "           2       0.33      0.04      0.07       220\n",
      "           3       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.45      1000\n",
      "   macro avg       0.31      0.30      0.27      1000\n",
      "weighted avg       0.41      0.45      0.40      1000\n",
      "\n",
      "results for class Motivation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.97      0.77       634\n",
      "           1       0.57      0.07      0.12       366\n",
      "\n",
      "    accuracy                           0.64      1000\n",
      "   macro avg       0.61      0.52      0.45      1000\n",
      "weighted avg       0.62      0.64      0.53      1000\n",
      "\n",
      "############### Embeddings: concatenated ####################\n",
      "results for class Humour:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.17      0.24       227\n",
      "           1       0.39      0.58      0.47       343\n",
      "           2       0.40      0.48      0.44       341\n",
      "           3       0.00      0.00      0.00        89\n",
      "\n",
      "    accuracy                           0.40      1000\n",
      "   macro avg       0.31      0.31      0.29      1000\n",
      "weighted avg       0.37      0.40      0.37      1000\n",
      "\n",
      "results for class Sarcasm:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.03      0.06       249\n",
      "           1       0.50      0.98      0.66       491\n",
      "           2       0.29      0.02      0.04       214\n",
      "           3       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.49      1000\n",
      "   macro avg       0.32      0.26      0.19      1000\n",
      "weighted avg       0.43      0.49      0.35      1000\n",
      "\n",
      "results for class Offense:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.61      0.53       399\n",
      "           1       0.42      0.53      0.47       352\n",
      "           2       0.41      0.06      0.10       220\n",
      "           3       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.44      1000\n",
      "   macro avg       0.32      0.30      0.27      1000\n",
      "weighted avg       0.42      0.44      0.40      1000\n",
      "\n",
      "results for class Motivation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.97      0.77       634\n",
      "           1       0.56      0.07      0.13       366\n",
      "\n",
      "    accuracy                           0.64      1000\n",
      "   macro avg       0.60      0.52      0.45      1000\n",
      "weighted avg       0.61      0.64      0.54      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "lr_ovc_oc = MultiOutputClassifier(OrdinalClassifier(LogisticRegression(random_state=0, solver=\"lbfgs\")))\n",
    "res_c_lr = evaluate(lr_ovc_oc, embed, y_train_c, y_dev_c, multitask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Embeddings: image only ####################\n"
     ]
    }
   ],
   "source": [
    "svm_ovc_oc = MultiOutputClassifier(OrdinalClassifier(SVC(probability=True)))\n",
    "res_c_svc = evaluate(svm_ovc_oc, embed, y_train_c, y_dev_c, multitask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rf_ovc_oc = MultiOutputClassifier(OrdinalClassifier(RandomForestClassifier(random_state=0)))\n",
    "res_c_rf = evaluate(rf_ovc_oc, embed, y_train_c, y_dev_c, multitask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
