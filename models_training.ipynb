{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 8 of Semeval 2020: Memotion analysis\n",
    "## Models training and evaluation\n",
    "This task is divided into 3 subtasks which are detailed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from joblib import dump, load\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from src.models.ordinal_regression import OrdinalClassifier\n",
    "from src.utils.files import load_dfs\n",
    "from src.utils.embeddings import retrieve_all_embeds\n",
    "from src.utils.reports import generate_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"data/models/custom\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(clf, embeds, y_train, y_dev, filename, multitask=False):\n",
    "    res = {}\n",
    "    for item, (X_train, X_dev, X_test) in embeds.items():\n",
    "        jobfile = \"{}/{}_{}.joblib\".format(model_path, filename, \"_\".join(item.split()))\n",
    "        print(\"############### Embeddings: {} ####################\".format(item))\n",
    "        if clf is None:\n",
    "            load(jobfile)\n",
    "        else:\n",
    "            clf.fit(X_train, y_train)\n",
    "            dump(clf, jobfile) \n",
    "        y_pred_dev = clf.predict(X_dev)\n",
    "        y_pred_test = clf.predict(X_test)\n",
    "        if not multitask:\n",
    "            rep = classification_report(y_dev, y_pred_dev)\n",
    "            print(rep)\n",
    "        else:\n",
    "            rep = [classification_report(y_dev[:,col], y_pred_dev[:,col]) for col in range(y_dev.shape[1])]\n",
    "            cols = [\"Humour\", \"Sarcasm\", \"Offense\", \"Motivation\"]\n",
    "            for c, r in list(zip(cols, rep)):\n",
    "                print(\"results for class {}:\\n{}\".format(c, r))\n",
    "        res[item] = {\"pred_cls_dev\": y_pred_dev, \"report_str\": rep, \"pred_cls_test\": y_pred_test}\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_train, df_dev = load_dfs([\"data/train_cleaned_final.csv\", \"data/dev_cleaned_final.csv\"])\n",
    "embed = retrieve_all_embeds([(\"data/features/use.pkl.train\", \"data/features/xception.pkl.train\"), \n",
    "                             (\"data/features/use.pkl.dev\",\"data/features/xception.pkl.dev\"),\n",
    "                             (\"data/features/use.pkl.test\", \"data/features/xception.pkl.test\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A: sentiment polarity detection\n",
    "Classify memes as negative, neutral or positive. More details here: https://competitions.codalab.org/competitions/20629\n",
    "We compare the results of Ordinal classifier with logistic regression, SVM and random forest.\n",
    "To investigate how each modality contributes to the detection, we test these models with embeddings of sentences only, \n",
    "images only and both concatenated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_train_a = df_train[\"Overall_sentiment\"].cat.codes\n",
    "y_dev_a = df_dev[\"Overall_sentiment\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_dev_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lr_oc = None\n",
    "# Uncomment for training the model instead of using the pretrained one\n",
    "# lr_oc = OrdinalClassifier(LogisticRegressionCV(cv=5, random_state=0, solver=\"saga\", max_iter=10000, n_jobs=6))\n",
    "\n",
    "res_a_lr = evaluate(lr_oc, embed, y_train_a, y_dev_a, \"task_a_lr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "knn_oc = None\n",
    "# Uncomment for training the model instead of using the pretrained one\n",
    "# knn_oc = OrdinalClassifier(KNeighborsClassifier(n_jobs=6))\n",
    "\n",
    "res_a_knn = evaluate(knn_oc, embed, y_train_a, y_dev_a, \"task_a_knn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gnb_oc = None\n",
    "# Uncomment for training the model instead of using the pretrained one\n",
    "# gnb_oc = OrdinalClassifier(GaussianNB())\n",
    "\n",
    "res_a_gnb = evaluate(gnb_oc, embed, y_train_a, y_dev_a, \"task_a_gnb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "abc_oc = None\n",
    "# Uncomment for training the model instead of using the pretrained one\n",
    "# abc_oc = OrdinalClassifier(AdaBoostClassifier(n_estimators=100, random_state=0))\n",
    "\n",
    "res_a_abc = evaluate(abc_oc, embed, y_train_a, y_dev_a, \"task_a_abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rf_oc = None\n",
    "# Uncomment for training the model instead of using the pretrained one\n",
    "# rf_oc = OrdinalClassifier(RandomForestClassifier(random_state=0, oob_score=True, n_jobs=6))\n",
    "\n",
    "res_a_rf = evaluate(rf_oc, embed, y_train_a, y_dev_a, \"task_a_rf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mlp_oc = None\n",
    "# Uncomment for training the model instead of using the pretrained one\n",
    "# mlp_oc = OrdinalClassifier(MLPClassifier(max_iter=1000))\n",
    "\n",
    "res_a_mlp = evaluate(mlp_oc, embed, y_train_a, y_dev_a, \"task_a_mlp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task B: Multilabel sentiment detection\n",
    "Classify memes as Humourous, sarcastics, offensive and/or motivationnal. One meme can have multiple sentiments.\n",
    "More details here: https://competitions.codalab.org/competitions/20629\n",
    "We compare the results of OneVsRest classifier with logistic regression, SVM and random forest.\n",
    "To investigate how each modality contributes to the detection, we test these models with embeddings of sentences only, \n",
    "images only and both concatenated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_b = df_train[[\"Humour_bin\", \"Sarcasm_bin\", \"Offense_bin\", \"Motivation_bin\"]].to_numpy().astype(int)\n",
    "y_dev_b = df_dev[[\"Humour_bin\", \"Sarcasm_bin\", \"Offense_bin\", \"Motivation_bin\"]].to_numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_dev_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_ovc = None\n",
    "# Uncomment for training the model instead of using the pretrained one\n",
    "# lr_ovc = OneVsRestClassifier(LogisticRegressionCV(cv=5, random_state=0, solver=\"saga\", max_iter=10000, n_jobs=6))\n",
    "\n",
    "res_b_lr = evaluate(lr_ovc, embed, y_train_b, y_dev_b, \"task_b_lr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "knn_ovc = None\n",
    "# Uncomment for training the model instead of using the pretrained one\n",
    "# knn_ovc = OneVsRestClassifier(KNeighborsClassifier(n_jobs=6))\n",
    "\n",
    "res_b_knn = evaluate(knn_ovc, embed, y_train_b, y_dev_b, \"task_b_knn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_ovc = None\n",
    "# Uncomment for training the model instead of using the pretrained one\n",
    "# gnb_ovc = OneVsRestClassifier(GaussianNB())\n",
    "\n",
    "res_b_gnb = evaluate(gnb_ovc, embed, y_train_b, y_dev_b, \"task_b_gnb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc_ovc = None\n",
    "# Uncomment for training the model instead of using the pretrained one\n",
    "# abc_ovc = OneVsRestClassifier(AdaBoostClassifier(n_estimators=100, random_state=0))\n",
    "\n",
    "res_b_abc = evaluate(abc_ovc, embed, y_train_b, y_dev_b, \"task_b_abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rf_ovc = None\n",
    "# Uncomment for training the model instead of using the pretrained one\n",
    "# rf_ovc = OneVsRestClassifier(RandomForestClassifier(random_state=0,oob_score=True, n_jobs=6))\n",
    "\n",
    "res_b_rf = evaluate(rf_ovc, embed, y_train_b, y_dev_b, \"task_b_rf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mlp_ovc = None\n",
    "# Uncomment for training the model instead of using the pretrained one\n",
    "# mlp_ovc = OneVsRestClassifier(MLPClassifier(max_iter=1000))\n",
    "\n",
    "res_b_mlp = evaluate(mlp_ovc, embed, y_train_b, y_dev_b, \"task_b_mlp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task C: Multilabel sentiment intensity detection\n",
    "Classify the degree of humour, sarcasm, offense and motivation of each meme. \n",
    "One meme can have multiple sentiments of different intensities. Each sentiment intensity is ranked from 0 (not at all) \n",
    "to 5 (very much).\n",
    "More details here: https://competitions.codalab.org/competitions/20629\n",
    "We compare the results of OneVsRest Ordinal classifier with logistic regression, SVM and random forest.\n",
    "To investigate how each modality contributes to the detection, we test these models with embeddings of sentences only, \n",
    "images only and both concatenated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"Humour\", \"Sarcasm\", \"Offense\", \"Motivation\"]\n",
    "y_train_c = pd.concat([df_train[name].cat.codes for name in cols], axis=1).to_numpy()\n",
    "y_dev_c = pd.concat([df_dev[name].cat.codes for name in cols], axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_reports(res_a, res_b, res_c, model_name):\n",
    "    configs = [\"text only\",\"image only\", \"concatenated\"]\n",
    "    for c in configs:\n",
    "        task_a = res_a_lr[c][\"pred_cls_test\"]\n",
    "        task_b = res_b_lr[c][\"pred_cls_test\"]\n",
    "        task_c = res_c_lr[c][\"pred_cls_test\"]\n",
    "        r = generate_report(task_a, task_b, task_c, zipname=\"res_{}_{}.zip\".format(model_name, \"_\".join(c.split())))\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lr_ovc_oc = None\n",
    "# Uncomment for training the model instead of using the pretrained one\n",
    "# lr_ovc_oc = MultiOutputClassifier(OrdinalClassifier(LogisticRegressionCV(cv=5, random_state=0, solver=\"saga\", max_iter=10000, n_jobs=6)))\n",
    "\n",
    "res_c_lr = evaluate(lr_ovc_oc, embed, y_train_c, y_dev_c, \"task_c_lr\", multitask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Embeddings: image only ####################\n",
      "results for class Humour:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.26      0.22       227\n",
      "           1       0.33      0.40      0.36       343\n",
      "           2       0.31      0.22      0.26       341\n",
      "           3       0.04      0.01      0.02        89\n",
      "\n",
      "    accuracy                           0.27      1000\n",
      "   macro avg       0.22      0.22      0.21      1000\n",
      "weighted avg       0.26      0.27      0.26      1000\n",
      "\n",
      "results for class Sarcasm:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.29      0.29       249\n",
      "           1       0.50      0.64      0.56       491\n",
      "           2       0.17      0.10      0.13       214\n",
      "           3       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.41      1000\n",
      "   macro avg       0.24      0.26      0.25      1000\n",
      "weighted avg       0.36      0.41      0.38      1000\n",
      "\n",
      "results for class Offense:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.60      0.49       399\n",
      "           1       0.35      0.35      0.35       352\n",
      "           2       0.18      0.06      0.09       220\n",
      "           3       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.38      1000\n",
      "   macro avg       0.24      0.25      0.23      1000\n",
      "weighted avg       0.33      0.38      0.34      1000\n",
      "\n",
      "results for class Motivation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.74      0.67       634\n",
      "           1       0.32      0.22      0.26       366\n",
      "\n",
      "    accuracy                           0.55      1000\n",
      "   macro avg       0.47      0.48      0.47      1000\n",
      "weighted avg       0.51      0.55      0.52      1000\n",
      "\n",
      "############### Embeddings: text only ####################\n",
      "results for class Humour:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.50      0.46       227\n",
      "           1       0.47      0.61      0.53       343\n",
      "           2       0.52      0.40      0.45       341\n",
      "           3       0.37      0.11      0.17        89\n",
      "\n",
      "    accuracy                           0.47      1000\n",
      "   macro avg       0.45      0.41      0.41      1000\n",
      "weighted avg       0.47      0.47      0.46      1000\n",
      "\n",
      "results for class Sarcasm:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.39      0.42       249\n",
      "           1       0.59      0.79      0.67       491\n",
      "           2       0.46      0.24      0.32       214\n",
      "           3       0.50      0.04      0.08        46\n",
      "\n",
      "    accuracy                           0.54      1000\n",
      "   macro avg       0.50      0.37      0.37      1000\n",
      "weighted avg       0.52      0.54      0.51      1000\n",
      "\n",
      "results for class Offense:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.73      0.59       399\n",
      "           1       0.54      0.53      0.54       352\n",
      "           2       0.56      0.17      0.26       220\n",
      "           3       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.52      1000\n",
      "   macro avg       0.40      0.36      0.35      1000\n",
      "weighted avg       0.51      0.52      0.48      1000\n",
      "\n",
      "results for class Motivation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.84      0.76       634\n",
      "           1       0.56      0.34      0.43       366\n",
      "\n",
      "    accuracy                           0.66      1000\n",
      "   macro avg       0.62      0.59      0.59      1000\n",
      "weighted avg       0.64      0.66      0.64      1000\n",
      "\n",
      "############### Embeddings: concatenated ####################\n",
      "results for class Humour:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.48      0.42       227\n",
      "           1       0.46      0.55      0.50       343\n",
      "           2       0.50      0.40      0.45       341\n",
      "           3       0.43      0.11      0.18        89\n",
      "\n",
      "    accuracy                           0.45      1000\n",
      "   macro avg       0.44      0.39      0.39      1000\n",
      "weighted avg       0.45      0.45      0.44      1000\n",
      "\n",
      "results for class Sarcasm:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.42      0.45       249\n",
      "           1       0.58      0.80      0.67       491\n",
      "           2       0.49      0.20      0.28       214\n",
      "           3       0.22      0.04      0.07        46\n",
      "\n",
      "    accuracy                           0.54      1000\n",
      "   macro avg       0.44      0.37      0.37      1000\n",
      "weighted avg       0.52      0.54      0.51      1000\n",
      "\n",
      "results for class Offense:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.72      0.60       399\n",
      "           1       0.54      0.54      0.54       352\n",
      "           2       0.54      0.20      0.30       220\n",
      "           3       0.67      0.07      0.12        29\n",
      "\n",
      "    accuracy                           0.52      1000\n",
      "   macro avg       0.56      0.38      0.39      1000\n",
      "weighted avg       0.53      0.52      0.50      1000\n",
      "\n",
      "results for class Motivation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.86      0.77       634\n",
      "           1       0.58      0.34      0.43       366\n",
      "\n",
      "    accuracy                           0.67      1000\n",
      "   macro avg       0.64      0.60      0.60      1000\n",
      "weighted avg       0.65      0.67      0.64      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_ovc_oc = None\n",
    "# Uncomment for training the model instead of using the pretrained one\n",
    "# knn_ovc_oc = MultiOutputClassifier(OrdinalClassifier(KNeighborsClassifier(n_jobs=6)))\n",
    "\n",
    "res_c_knn = evaluate(knn_ovc_oc, embed, y_train_c, y_dev_c, \"task_c_knn\", multitask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Embeddings: image only ####################\n",
      "results for class Humour:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.77      0.36       227\n",
      "           1       0.38      0.10      0.15       343\n",
      "           2       0.38      0.11      0.16       341\n",
      "           3       0.10      0.07      0.08        89\n",
      "\n",
      "    accuracy                           0.25      1000\n",
      "   macro avg       0.27      0.26      0.19      1000\n",
      "weighted avg       0.32      0.25      0.20      1000\n",
      "\n",
      "results for class Sarcasm:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.71      0.36       249\n",
      "           1       0.46      0.12      0.19       491\n",
      "           2       0.22      0.09      0.13       214\n",
      "           3       0.03      0.02      0.02        46\n",
      "\n",
      "    accuracy                           0.26      1000\n",
      "   macro avg       0.24      0.24      0.18      1000\n",
      "weighted avg       0.33      0.26      0.21      1000\n",
      "\n",
      "results for class Offense:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.77      0.53       399\n",
      "           1       0.37      0.10      0.15       352\n",
      "           2       0.20      0.09      0.12       220\n",
      "           3       0.05      0.07      0.06        29\n",
      "\n",
      "    accuracy                           0.36      1000\n",
      "   macro avg       0.25      0.26      0.21      1000\n",
      "weighted avg       0.33      0.36      0.29      1000\n",
      "\n",
      "results for class Motivation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.24      0.36       634\n",
      "           1       0.38      0.80      0.51       366\n",
      "\n",
      "    accuracy                           0.45      1000\n",
      "   macro avg       0.53      0.52      0.44      1000\n",
      "weighted avg       0.57      0.45      0.41      1000\n",
      "\n",
      "############### Embeddings: text only ####################\n",
      "results for class Humour:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.30      0.32       227\n",
      "           1       0.43      0.37      0.40       343\n",
      "           2       0.39      0.47      0.43       341\n",
      "           3       0.22      0.22      0.22        89\n",
      "\n",
      "    accuracy                           0.38      1000\n",
      "   macro avg       0.34      0.34      0.34      1000\n",
      "weighted avg       0.38      0.38      0.37      1000\n",
      "\n",
      "results for class Sarcasm:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.34      0.33       249\n",
      "           1       0.52      0.55      0.53       491\n",
      "           2       0.30      0.24      0.27       214\n",
      "           3       0.22      0.24      0.23        46\n",
      "\n",
      "    accuracy                           0.42      1000\n",
      "   macro avg       0.34      0.34      0.34      1000\n",
      "weighted avg       0.41      0.42      0.41      1000\n",
      "\n",
      "results for class Offense:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.54      0.51       399\n",
      "           1       0.43      0.34      0.38       352\n",
      "           2       0.33      0.30      0.31       220\n",
      "           3       0.07      0.17      0.10        29\n",
      "\n",
      "    accuracy                           0.40      1000\n",
      "   macro avg       0.33      0.34      0.32      1000\n",
      "weighted avg       0.42      0.40      0.41      1000\n",
      "\n",
      "results for class Motivation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.69      0.68       634\n",
      "           1       0.44      0.41      0.42       366\n",
      "\n",
      "    accuracy                           0.59      1000\n",
      "   macro avg       0.55      0.55      0.55      1000\n",
      "weighted avg       0.59      0.59      0.59      1000\n",
      "\n",
      "############### Embeddings: concatenated ####################\n",
      "results for class Humour:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.77      0.36       227\n",
      "           1       0.38      0.10      0.15       343\n",
      "           2       0.38      0.11      0.16       341\n",
      "           3       0.10      0.07      0.08        89\n",
      "\n",
      "    accuracy                           0.25      1000\n",
      "   macro avg       0.27      0.26      0.19      1000\n",
      "weighted avg       0.32      0.25      0.20      1000\n",
      "\n",
      "results for class Sarcasm:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.71      0.36       249\n",
      "           1       0.47      0.12      0.20       491\n",
      "           2       0.22      0.09      0.13       214\n",
      "           3       0.02      0.02      0.02        46\n",
      "\n",
      "    accuracy                           0.26      1000\n",
      "   macro avg       0.24      0.24      0.18      1000\n",
      "weighted avg       0.34      0.26      0.21      1000\n",
      "\n",
      "results for class Offense:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.77      0.53       399\n",
      "           1       0.37      0.10      0.15       352\n",
      "           2       0.20      0.09      0.12       220\n",
      "           3       0.05      0.07      0.06        29\n",
      "\n",
      "    accuracy                           0.36      1000\n",
      "   macro avg       0.26      0.26      0.21      1000\n",
      "weighted avg       0.34      0.36      0.29      1000\n",
      "\n",
      "results for class Motivation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.24      0.36       634\n",
      "           1       0.38      0.80      0.51       366\n",
      "\n",
      "    accuracy                           0.45      1000\n",
      "   macro avg       0.52      0.52      0.43      1000\n",
      "weighted avg       0.56      0.45      0.41      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gnb_ovc_oc = None\n",
    "# Uncomment for training the model instead of using the pretrained one\n",
    "# gnb_ovc_oc = MultiOutputClassifier(OrdinalClassifier(GaussianNB()))\n",
    "\n",
    "res_c_gnb = evaluate(gnb_ovc_oc, embed, y_train_c, y_dev_c, \"task_c_gnb\", multitask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Embeddings: image only ####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for class Humour:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.83      0.35       227\n",
      "           1       0.00      0.00      0.00       343\n",
      "           2       0.00      0.00      0.00       341\n",
      "           3       0.12      0.21      0.15        89\n",
      "\n",
      "    accuracy                           0.21      1000\n",
      "   macro avg       0.09      0.26      0.13      1000\n",
      "weighted avg       0.06      0.21      0.09      1000\n",
      "\n",
      "results for class Sarcasm:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.90      0.39       249\n",
      "           1       0.00      0.00      0.00       491\n",
      "           2       0.00      0.00      0.00       214\n",
      "           3       0.02      0.04      0.03        46\n",
      "\n",
      "    accuracy                           0.23      1000\n",
      "   macro avg       0.07      0.23      0.10      1000\n",
      "weighted avg       0.06      0.23      0.10      1000\n",
      "\n",
      "results for class Offense:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.99      0.57       399\n",
      "           1       0.00      0.00      0.00       352\n",
      "           2       0.00      0.00      0.00       220\n",
      "           3       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.39      1000\n",
      "   macro avg       0.10      0.25      0.14      1000\n",
      "weighted avg       0.16      0.39      0.23      1000\n",
      "\n",
      "results for class Motivation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.86      0.73       634\n",
      "           1       0.32      0.11      0.17       366\n",
      "\n",
      "    accuracy                           0.59      1000\n",
      "   macro avg       0.47      0.49      0.45      1000\n",
      "weighted avg       0.51      0.59      0.52      1000\n",
      "\n",
      "############### Embeddings: text only ####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for class Humour:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.91      0.40       227\n",
      "           1       0.00      0.00      0.00       343\n",
      "           2       0.00      0.00      0.00       341\n",
      "           3       0.21      0.48      0.30        89\n",
      "\n",
      "    accuracy                           0.25      1000\n",
      "   macro avg       0.12      0.35      0.17      1000\n",
      "weighted avg       0.08      0.25      0.12      1000\n",
      "\n",
      "results for class Sarcasm:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.96      0.42       249\n",
      "           1       0.00      0.00      0.00       491\n",
      "           2       0.00      0.00      0.00       214\n",
      "           3       0.17      0.43      0.25        46\n",
      "\n",
      "    accuracy                           0.26      1000\n",
      "   macro avg       0.11      0.35      0.17      1000\n",
      "weighted avg       0.07      0.26      0.12      1000\n",
      "\n",
      "results for class Offense:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.99      0.57       399\n",
      "           1       0.00      0.00      0.00       352\n",
      "           2       0.00      0.00      0.00       220\n",
      "           3       0.29      0.14      0.19        29\n",
      "\n",
      "    accuracy                           0.40      1000\n",
      "   macro avg       0.17      0.28      0.19      1000\n",
      "weighted avg       0.17      0.40      0.23      1000\n",
      "\n",
      "results for class Motivation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.89      0.77       634\n",
      "           1       0.60      0.28      0.39       366\n",
      "\n",
      "    accuracy                           0.67      1000\n",
      "   macro avg       0.64      0.59      0.58      1000\n",
      "weighted avg       0.65      0.67      0.63      1000\n",
      "\n",
      "############### Embeddings: concatenated ####################\n",
      "results for class Humour:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.85      0.38       227\n",
      "           1       0.00      0.00      0.00       343\n",
      "           2       0.00      0.00      0.00       341\n",
      "           3       0.16      0.40      0.23        89\n",
      "\n",
      "    accuracy                           0.23      1000\n",
      "   macro avg       0.10      0.31      0.15      1000\n",
      "weighted avg       0.07      0.23      0.11      1000\n",
      "\n",
      "results for class Sarcasm:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.92      0.40       249\n",
      "           1       0.00      0.00      0.00       491\n",
      "           2       0.00      0.00      0.00       214\n",
      "           3       0.09      0.22      0.13        46\n",
      "\n",
      "    accuracy                           0.24      1000\n",
      "   macro avg       0.09      0.29      0.13      1000\n",
      "weighted avg       0.07      0.24      0.11      1000\n",
      "\n",
      "results for class Offense:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.98      0.57       399\n",
      "           1       0.00      0.00      0.00       352\n",
      "           2       0.00      0.00      0.00       220\n",
      "           3       0.11      0.07      0.08        29\n",
      "\n",
      "    accuracy                           0.39      1000\n",
      "   macro avg       0.13      0.26      0.16      1000\n",
      "weighted avg       0.16      0.39      0.23      1000\n",
      "\n",
      "results for class Motivation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.85      0.75       634\n",
      "           1       0.49      0.25      0.34       366\n",
      "\n",
      "    accuracy                           0.63      1000\n",
      "   macro avg       0.58      0.55      0.54      1000\n",
      "weighted avg       0.60      0.63      0.60      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "abc_ovc_oc = None\n",
    "# Uncomment for training the model instead of using the pretrained one\n",
    "# abc_ovc_oc = MultiOutputClassifier(OrdinalClassifier(AdaBoostClassifier(n_estimators=100, random_state=0)))\n",
    "\n",
    "res_c_abc = evaluate(abc_ovc_oc, embed, y_train_c, y_dev_c, \"task_c_abc\", multitask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Embeddings: image only ####################\n",
      "results for class Humour:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.20      0.20       227\n",
      "           1       0.36      0.39      0.37       343\n",
      "           2       0.33      0.30      0.32       341\n",
      "           3       0.11      0.10      0.11        89\n",
      "\n",
      "    accuracy                           0.29      1000\n",
      "   macro avg       0.25      0.25      0.25      1000\n",
      "weighted avg       0.29      0.29      0.29      1000\n",
      "\n",
      "results for class Sarcasm:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.23      0.26       249\n",
      "           1       0.50      0.57      0.53       491\n",
      "           2       0.20      0.17      0.18       214\n",
      "           3       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.38      1000\n",
      "   macro avg       0.25      0.24      0.24      1000\n",
      "weighted avg       0.36      0.38      0.37      1000\n",
      "\n",
      "results for class Offense:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.45      0.42       399\n",
      "           1       0.37      0.35      0.36       352\n",
      "           2       0.23      0.20      0.21       220\n",
      "           3       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.35      1000\n",
      "   macro avg       0.25      0.25      0.25      1000\n",
      "weighted avg       0.34      0.35      0.34      1000\n",
      "\n",
      "results for class Motivation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.70      0.67       634\n",
      "           1       0.37      0.30      0.33       366\n",
      "\n",
      "    accuracy                           0.56      1000\n",
      "   macro avg       0.50      0.50      0.50      1000\n",
      "weighted avg       0.54      0.56      0.54      1000\n",
      "\n",
      "############### Embeddings: text only ####################\n",
      "results for class Humour:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.87       227\n",
      "           1       0.84      0.85      0.85       343\n",
      "           2       0.81      0.86      0.84       341\n",
      "           3       0.96      0.79      0.86        89\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.88      0.84      0.85      1000\n",
      "weighted avg       0.85      0.85      0.85      1000\n",
      "\n",
      "results for class Sarcasm:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.80      0.86       249\n",
      "           1       0.83      0.96      0.89       491\n",
      "           2       0.95      0.79      0.87       214\n",
      "           3       0.97      0.76      0.85        46\n",
      "\n",
      "    accuracy                           0.88      1000\n",
      "   macro avg       0.92      0.83      0.87      1000\n",
      "weighted avg       0.89      0.88      0.87      1000\n",
      "\n",
      "results for class Offense:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.91      0.85       399\n",
      "           1       0.85      0.82      0.84       352\n",
      "           2       0.95      0.80      0.87       220\n",
      "           3       1.00      0.66      0.79        29\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.90      0.80      0.84      1000\n",
      "weighted avg       0.86      0.85      0.85      1000\n",
      "\n",
      "results for class Motivation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94       634\n",
      "           1       0.98      0.80      0.88       366\n",
      "\n",
      "    accuracy                           0.92      1000\n",
      "   macro avg       0.94      0.89      0.91      1000\n",
      "weighted avg       0.93      0.92      0.92      1000\n",
      "\n",
      "############### Embeddings: concatenated ####################\n",
      "results for class Humour:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.48      0.52       227\n",
      "           1       0.51      0.66      0.58       343\n",
      "           2       0.51      0.52      0.51       341\n",
      "           3       0.60      0.13      0.22        89\n",
      "\n",
      "    accuracy                           0.52      1000\n",
      "   macro avg       0.55      0.45      0.46      1000\n",
      "weighted avg       0.53      0.52      0.51      1000\n",
      "\n",
      "results for class Sarcasm:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.20      0.29       249\n",
      "           1       0.52      0.89      0.66       491\n",
      "           2       0.33      0.08      0.13       214\n",
      "           3       0.40      0.09      0.14        46\n",
      "\n",
      "    accuracy                           0.51      1000\n",
      "   macro avg       0.44      0.32      0.31      1000\n",
      "weighted avg       0.47      0.51      0.43      1000\n",
      "\n",
      "results for class Offense:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.76      0.59       399\n",
      "           1       0.51      0.47      0.49       352\n",
      "           2       0.67      0.14      0.23       220\n",
      "           3       0.33      0.03      0.06        29\n",
      "\n",
      "    accuracy                           0.50      1000\n",
      "   macro avg       0.50      0.35      0.34      1000\n",
      "weighted avg       0.53      0.50      0.46      1000\n",
      "\n",
      "results for class Motivation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.98      0.78       634\n",
      "           1       0.68      0.08      0.14       366\n",
      "\n",
      "    accuracy                           0.65      1000\n",
      "   macro avg       0.67      0.53      0.46      1000\n",
      "weighted avg       0.66      0.65      0.54      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_ovc_oc = None\n",
    "# Uncomment for training the model instead of using the pretrained one\n",
    "# rf_ovc_oc = MultiOutputClassifier(OrdinalClassifier(RandomForestClassifier(random_state=0, oob_score=True, n_jobs=6)))\n",
    "\n",
    "res_c_rf = evaluate(rf_ovc_oc, embed, y_train_c, y_dev_c, \"task_c_rf\", multitask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Embeddings: image only ####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb732/Projects/memotion_analysis/.venv/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mlp_ovc_oc = None\n",
    "# Uncomment for training the model instead of using the pretrained one\n",
    "# mlp_ovc_oc = MultiOutputClassifier(OrdinalClassifier(MLPClassifier(max_iter=1000)))\n",
    "\n",
    "res_c_mlp = evaluate(mlp_ovc_oc, embed, y_train_c, y_dev_c, \"task_c_mlp\", multitask=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating report\n",
    "We take the results of the best classifier for each task, here the random forest and generate a report following the guidelines provided here: https://competitions.codalab.org/competitions/20629#learn_the_details-submission-guidelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_reports(res_a_lr, res_b_lr, res_c_lr, \"lr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_reports(res_a_knn, res_b_knn, res_c_knn, \"knn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_reports(res_a_gnb, res_b_gnb, res_c_gnb, \"gnb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_reports(res_a_abc, res_b_abc, res_c_abc, \"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_reports(res_a_rf, res_b_rf, res_c_rf, \"rf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_reports(res_a_mlp, res_b_mlp, res_c_mlp, \"mlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
